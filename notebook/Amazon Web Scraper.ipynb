{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d29e751-1ee8-44a3-ac8b-d419a1a511a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries needed for the web scraping project\n",
    "from bs4 import BeautifulSoup  # To parse HTML content\n",
    "import requests  # To make HTTP requests to websites\n",
    "import time  # To add sleep intervals for looping\n",
    "import datetime  # To work with date and time\n",
    "import smtplib  # To send email notifications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b9c6abd-a0bb-414f-b4ad-ae22c386740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the URL of the product you want to scrape\n",
    "url = 'https://www.amazon.co.uk/Apple-iPhone-15-128-GB/dp/B0CHX3RPHZ/ref=sr_1_1_sspa?crid=3C54B0GO9TVKX&dib=eyJ2IjoiMSJ9.ZIvfLG9rkG36sPq4SXKS3gqmDUfhmWtkE2sMG81-tq-u8z2JYYCNo4lv8Zitotoy95s7fvTlsqjRSu-46hs9Cjdz76mbnSrYImvTcsGtTUKsbGXcRYqlATkp8-AWEbZxiP53uBAMlnj3v12C5BOjFupPJK0PloZ9K5KxTytKRdijk7iXhmgHTug_NyVhUaFzRKDewMZDHd8ZXqb8ZijcE3sf9JrovbmKTBcJef4OPGI.mkiP_bMBb1knlcBLmvImeLrfIfff26j32Y_k0K6Ljrs&dib_tag=se&keywords=iphone&qid=1725551476&sprefix=iphone%2Caps%2C197&sr=8-1-spons&sp_csd=d2lkZ2V0TmFtZT1zcF9hdGY&psc=1'\n",
    "\n",
    "# Step 2: Set up headers to mimic a browser request\n",
    "# These headers help Amazon recognize the request as coming from a browser\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36\",\n",
    "    \"Sec-Fetch-Mode\": \"navigate\", \n",
    "    \"Sec-Fetch-Site\": \"none\", \n",
    "    \"Sec-Fetch-User\": \"?1\", \n",
    "    \"Upgrade-Insecure-Requests\": \"1\", \n",
    "    \"X-Amzn-Trace-Id\": \"Root=1-66d9d341-22d960847d4a2e833c263cd5\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65f12038-17f7-4da2-838b-d706098563e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Fetch the page content\n",
    "# Use requests to get the webpage's HTML content\n",
    "page = requests.get(url, headers=headers)\n",
    "\n",
    "# Step 4: Parse the HTML using BeautifulSoup\n",
    "# Parse the page content with BeautifulSoup\n",
    "soup1 = BeautifulSoup(page.content, \"html.parser\")  # Get the raw HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b65ff7f7-ecb7-4547-b217-06909d78291e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Apple iPhone 15 (128 GB) - Blue\n",
      "Price: £687..00\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Extract the Product Title\n",
    "# Use the HTML \"id\" tag to locate and extract the title of the product\n",
    "title = soup1.find(id=\"productTitle\").get_text().strip()  # .strip() removes unnecessary spaces\n",
    "print(f\"Product: {title}\")  # Print the product title to verify\n",
    "\n",
    "# Step 6: Extract the Product Price\n",
    "# Extract the Whole and Fractional Price\n",
    "\n",
    "# Get the whole part of the price (e.g., \"687\"), handling any extra spaces or newline characters\n",
    "whole_price = soup1.find(\"span\", {\"class\": \"a-price-whole\"}).get_text().strip()\n",
    "\n",
    "# Check if the fractional part exists, handle cases where it might be missing\n",
    "fractional_price_element = soup1.find(\"span\", {\"class\": \"a-price-fraction\"})\n",
    "\n",
    "if fractional_price_element:\n",
    "    # Get the fractional part, but handle extra spaces and ensure it's cleaned\n",
    "    fractional_price = fractional_price_element.get_text().strip()\n",
    "else:\n",
    "    # Default fractional price if it's missing (for prices like \"£687\" with no decimals)\n",
    "    fractional_price = \"00\"\n",
    "\n",
    "# Ensure both whole_price and fractional_price are cleaned up correctly\n",
    "whole_price = whole_price.replace(\",\", \"\").strip()  # Remove commas and extra spaces\n",
    "fractional_price = fractional_price.strip()  # Clean any spaces in the fractional part\n",
    "\n",
    "# Combine the whole and fractional parts\n",
    "# Fix: Use string concatenation carefully to avoid extra periods or characters\n",
    "price = f\"{whole_price}.{fractional_price}\".strip()  # Strip ensures no extra spaces or periods\n",
    "\n",
    "# Print the cleaned-up price to verify the output\n",
    "print(f\"Price: £{price}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d490cfd6-d3c7-47c7-9b81-a822e6431995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2024-09-05\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Add a Date Stamp\n",
    "# Track the date when the product price was scraped for historical reference\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "print(f\"Date: {today}\")  # Print the current date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84c286a7-19e3-44c4-9b90-32738cd8b216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved: ['Apple iPhone 15 (128 GB) - Blue', '687..00', '2024-09-05']\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Save the Data to a CSV file\n",
    "# Import the CSV module to handle CSV file operations\n",
    "import csv\n",
    "\n",
    "# We'll store the product title, price, and date in a CSV file\n",
    "header = ['Product', 'Price', 'Date']  # CSV headers\n",
    "data = [title, price, today]  # The data we want to store\n",
    "\n",
    "# Create a CSV file (or open if it exists) and write the data\n",
    "with open('AmazonWebScraperDataset.csv', 'w', newline='', encoding='UTF8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)  # Write the header (only once)\n",
    "    writer.writerow(data)  # Write the data (title, price, date)\n",
    "# Confirm data has been saved\n",
    "    print(f\"Data saved: {data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "809af76e-6846-46c9-ac80-1ec001528808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Product    Price        Date\n",
      "0  Apple iPhone 15 (128 GB) - Blue  687..00  2024-09-05\n"
     ]
    }
   ],
   "source": [
    "# Import pandas to read the CSV file\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file to verify the data has been saved\n",
    "df = pd.read_csv(r'AmazonWebScraperDataset.csv')\n",
    "\n",
    "# Print the dataframe to check the content\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d1ba46d0-d7cb-4237-938e-4de1e1a58cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch data and append it to the existing CSV file\n",
    "def check_price():\n",
    "    page = requests.get(url, headers=headers)\n",
    "    soup1 = BeautifulSoup(page.content, \"html.parser\")\n",
    "    \n",
    "    # Extract the product title\n",
    "    title = soup1.find(id=\"productTitle\").get_text().strip()\n",
    "    \n",
    "    # Extract the price using the fixed logic\n",
    "    whole_price = soup1.find(\"span\", {\"class\": \"a-price-whole\"}).get_text().strip()\n",
    "    fractional_price_element = soup1.find(\"span\", {\"class\": \"a-price-fraction\"})\n",
    "    \n",
    "    if fractional_price_element:\n",
    "        fractional_price = fractional_price_element.get_text().strip()\n",
    "    else:\n",
    "        fractional_price = \"00\"\n",
    "    \n",
    "    price = f\"{whole_price}.{fractional_price}\".strip()\n",
    "\n",
    "    # Add the current date\n",
    "    today = datetime.today().strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Append data to the CSV\n",
    "    data = [title, price, today]\n",
    "    with open('AmazonWebScraperDataset.csv', 'a+', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(data)\n",
    "    \n",
    "    # Print the data for verification\n",
    "    print(f\"Data scraped and saved: {data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f30aa688-f1bb-4b9b-ba10-6aeb769d7c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scraped and saved: ['Apple iPhone 15 (128 GB) - Blue', '687..00', '2024-09-05']\n",
      "Iteration 1 complete.\n",
      "Data scraped and saved: ['Apple iPhone 15 (128 GB) - Blue', '687..00', '2024-09-05']\n",
      "Iteration 2 complete.\n",
      "Data scraped and saved: ['Apple iPhone 15 (128 GB) - Blue', '687..00', '2024-09-05']\n",
      "Iteration 3 complete.\n",
      "Data scraped and saved: ['Apple iPhone 15 (128 GB) - Blue', '687..00', '2024-09-05']\n",
      "Iteration 4 complete.\n",
      "Data scraped and saved: ['Apple iPhone 15 (128 GB) - Blue', '687..00', '2024-09-05']\n",
      "Iteration 5 complete.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Test: Run the scraper every 2 seconds for 5 iterations\n",
    "for i in range(5):\n",
    "    check_price()  # Run the price check function\n",
    "    time.sleep(2)  # Wait for 2 seconds before the next run\n",
    "    print(f\"Iteration {i+1} complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a392b4d-7b6d-4892-9e63-e57b67a79fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Run the scraper repeatedly (automating the process)\n",
    "# The following loop runs the scraper at set intervals (e.g., once a day)\n",
    "import time\n",
    "\n",
    "# The loop will continuously scrape the product page and append new data every 24 hours (86400 seconds)\n",
    "while True:\n",
    "    check_price()  # Run the price check function\n",
    "    time.sleep(86400)  # Wait 24 hours before running the script again (86400 seconds in a day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9fd7d834-972f-4eb5-953e-2f32730ed878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Product    Price        Date\n",
      "0  Apple iPhone 15 (128 GB) - Blue  687..00  2024-09-05\n",
      "1  Apple iPhone 15 (128 GB) - Blue  687..00  2024-09-05\n",
      "2  Apple iPhone 15 (128 GB) - Blue  687..00  2024-09-05\n",
      "3  Apple iPhone 15 (128 GB) - Blue  687..00  2024-09-05\n",
      "4  Apple iPhone 15 (128 GB) - Blue  687..00  2024-09-05\n",
      "5  Apple iPhone 15 (128 GB) - Blue  687..00  2024-09-05\n",
      "6  Apple iPhone 15 (128 GB) - Blue  687..00  2024-09-05\n"
     ]
    }
   ],
   "source": [
    "# Import pandas to read the CSV file\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file to verify the data has been saved\n",
    "df = pd.read_csv(r'AmazonWebScraperDataset.csv')\n",
    "\n",
    "# Print the dataframe to check the content\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04787c1-b52d-44dd-adda-930afbf715d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f33a3a-5521-43c2-b03a-d3fa0a1d5930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
